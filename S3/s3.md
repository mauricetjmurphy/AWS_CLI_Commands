## Create a bucket
### Syntax

    $ aws s3 mb <target> [--options]

### Example

    $ aws s3 mb s3://bucket-name

## List buckets and objects
### Syntax

    $ aws s3 ls <target> [--options]

### Example

    $ aws s3 ls
    $ aws s3 ls s3://bucket-name
    $ aws s3 ls s3://bucket-name/example/

## Delete buckets
### Syntax

    $ aws s3 rb <target> [--options]

### Example

    $ aws s3 rb s3://bucket-name
    $ aws s3 rb s3://bucket-name --force

## Delete objects
### Syntax

    $ aws s3 rm  <target> [--options]

### Example

    $ aws s3 rm s3://bucket-name/example/filename.txt
    $ aws s3 rm s3://bucket-name/example --recursive

## Move objects
### Syntax

    $ aws s3 mv <source> <target> [--options]

### Examples

#### The following example moves all objects from s3://bucket-name/example to s3://my-bucket/.

    $ aws s3 mv s3://bucket-name/example s3://my-bucket/

#### The following example moves a local file from your current working directory to the Amazon S3 bucket with the s3 mv command.

    $ aws s3 mv filename.txt s3://bucket-name

#### The following example moves a file from your Amazon S3 bucket to your current working directory, where ./ specifies your current working directory.

    $ aws s3 mv s3://bucket-name/filename.txt ./

## Copy objects
### Syntax

    $ aws s3 cp <source> <target> [--options]

### Examples

#### The following example copies all objects from s3://bucket-name/example to s3://my-bucket/.

    $ aws s3 cp s3://bucket-name/example s3://my-bucket/

#### The following example copies a local file from your current working directory to the Amazon S3 bucket with the s3 cp command.

    $ aws s3 cp filename.txt s3://bucket-name

#### The following example copies a file from your Amazon S3 bucket to your current working directory, where ./ specifies your current working directory.

    $ aws s3 cp s3://bucket-name/filename.txt ./

#### The following example uses echo to stream the text "hello world" to the s3://bucket-name/filename.txt file.

    $ echo "hello world" | aws s3 cp - s3://bucket-name/filename.txt

#### The following example streams the s3://bucket-name/filename.txt file to stdout and prints the contents to the console.

    $ aws s3 cp s3://bucket-name/filename.txt

#### The following example streams the contents of s3://bucket-name/pre to stdout, uses the bzip2 command to compress the files, and uploads the new compressed file named key.bz2 to s3://bucket-name.

    $ aws s3 cp s3://bucket-name/pre - | bzip2 --best | aws s3 cp - s3://bucket-name/key.bz2

## Sync objects

#### The s3 sync command synchronizes the contents of a bucket and a directory, or the contents of two buckets. Typically, s3 sync copies missing or outdated files or objects between the source and target. However, you can also supply the --delete option to remove files or objects from the target that are not present in the source.

### Syntax

    $ aws s3 sync <source> <target> [--options]

#### The following example synchronizes the contents of an Amazon S3 prefix named path in the bucket named my-bucket with the current working directory.

s3 sync updates any files that have a size or modified time that are different from files with the same name at the destination. The output displays specific operations performed during the sync. Notice that the operation recursively synchronizes the subdirectory MySubdirectory and its contents with s3://my-bucket/path/MySubdirectory.

    $ aws s3 sync . s3://my-bucket/path

#### The following example, which extends the previous one, shows how to use the --delete option.

    // Delete local file
    $ rm ./MyFile1.txt

    // Attempt sync without --delete option - nothing happens
    $ aws s3 sync . s3://my-bucket/path

    // Sync with deletion - object is deleted from bucket
    $ aws s3 sync . s3://my-bucket/path --delete
    delete: s3://my-bucket/path/MyFile1.txt

    // Delete object from bucket
    $ aws s3 rm s3://my-bucket/path/MySubdirectory/MyFile3.txt
    delete: s3://my-bucket/path/MySubdirectory/MyFile3.txt

    // Sync with deletion - local file is deleted
    $ aws s3 sync s3://my-bucket/path . --delete
    delete: MySubdirectory\MyFile3.txt

    // Sync with Infrequent Access storage class
    $ aws s3 sync . s3://my-bucket/path --storage-class STANDARD_IA

## Frequently used options for s3 commands

#### The following options are frequently used for the commands described in this topic. For a complete list of options you can use on a command, see the specific command in the AWS CLI version 2 reference guide.

### acl
#### s3 sync and s3 cp can use the --acl option. This enables you to set the access permissions for files copied to Amazon S3. The --acl option accepts private, public-read, and public-read-write values. For more information, see Canned ACL in the Amazon Simple Storage Service User Guide.


    $ aws s3 sync . s3://my-bucket/path --acl public-read
### exclude
#### When you use the s3 cp, s3 mv, s3 sync, or s3 rm command, you can filter the results by using the --exclude or --include option. The --exclude option sets rules to only exclude objects from the command, and the options apply in the order specified. This is shown in the following example.


    Local directory contains 3 files:
    MyFile1.txt
    MyFile2.rtf
    MyFile88.txt

    // Exclude all .txt files, resulting in only MyFile2.rtf being copied
    $ aws s3 cp . s3://my-bucket/path --exclude "*.txt"

    // Exclude all .txt files but include all files with the "MyFile*.txt" format, resulting in, MyFile1.txt, MyFile2.rtf, MyFile88.txt being copied
    $ aws s3 cp . s3://my-bucket/path --exclude "*.txt" --include "MyFile*.txt"

    // Exclude all .txt files, but include all files with the "MyFile*.txt" format, but exclude all files with the "MyFile?.txt" format resulting in, MyFile2.rtf and MyFile88.txt being copied
    $ aws s3 cp . s3://my-bucket/path --exclude "*.txt" --include "MyFile*.txt" --exclude "MyFile?.txt"

### include
#### When you use the s3 cp, s3 mv, s3 sync, or s3 rm command, you can filter the results using the --exclude or --include option. The --include option sets rules to only include objects specified for the command, and the options apply in the order specified. This is shown in the following example.


    Local directory contains 3 files:
    MyFile1.txt
    MyFile2.rtf
    MyFile88.txt

    // Include all .txt files, resulting in MyFile1.txt and MyFile88.txt being copied
    $ aws s3 cp . s3://my-bucket/path --include "*.txt"

    // Include all .txt files but exclude all files with the "MyFile*.txt" format, resulting in no files being copied
    $ aws s3 cp . s3://my-bucket/path --include "*.txt" --exclude "MyFile*.txt"

    // Include all .txt files, but exclude all files with the "MyFile*.txt" format, but include all files with the "MyFile?.txt" format resulting in MyFile1.txt being copied

    $ aws s3 cp . s3://my-bucket/path --include "*.txt" --exclude "MyFile*.txt" --include "MyFile?.txt"

### grant
#### The s3 cp, s3 mv, and s3 sync commands include a --grants option that you can use to grant permissions on the object to specified users or groups. Set the --grants option to a list of permissions using the following syntax. Replace Permission, Grantee_Type, and Grantee_ID with your own values.

### Syntax

    --grants Permission=Grantee_Type=Grantee_ID
            [Permission=Grantee_Type=Grantee_ID ...]

### Each value contains the following elements:

#### Permission – Specifies the granted permissions. Can be set to read, readacl, writeacl, or full.

#### Grantee_Type – Specifies how to identify the grantee. Can be set to uri, emailaddress, or id.

#### Grantee_ID – Specifies the grantee based on Grantee_Type.

#### uri – The group's URI. For more information, see Who is a grantee?

#### emailaddress – The account's email address.

#### id – The account's canonical ID.

#### For more information about Amazon S3 access control, see Access control.

#### The following example copies an object into a bucket. It grants read permissions on the object to everyone, and full permissions (read, readacl, and writeacl) to the account associated with user@example.com.

    $ aws s3 cp file.txt s3://my-bucket/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=emailaddress=user@example.com

#### You can also specify a nondefault storage class (REDUCED_REDUNDANCY or STANDARD_IA) for objects that you upload to Amazon S3. To do this, use the --storage-class option.

    $ aws s3 cp file.txt s3://my-bucket/ --storage-class REDUCED_REDUNDANCY

### recursive

#### When you use this option, the command is performed on all files or objects under the specified directory or prefix. The following example deletes s3://my-bucket/path and all of its contents.

    $ aws s3 rm s3://my-bucket/path --recursive